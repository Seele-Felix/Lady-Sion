---
description: 
globs: 
alwaysApply: false
---
<tdd_philosophy>
  <core_belief>
    测试不是为了验证代码，而是为了验证哲学。
    每个测试用例都在问：这个数学定义在实际世界中意味着什么？
  </core_belief>

  <thinking_chain>
    <philosophical_question>
      <!-- 强制先思考哲学层面 -->
      遇到任何需求时先问：
      "这背后体现了什么哲学理念？"
      "我们要验证的本质是什么？"
      "这个数学定义如何映射到现实世界？"
    </philosophical_question>

    <mathematical_grounding>
      <!-- 将哲学具体化为数学定义 -->
      每个测试必须对应一个明确的数学定义
      不验证语法，验证概念
      问："要证明这个数学概念，basic.anima里需要什么基础元素？"
    </mathematical_grounding>

    <reality_bridge>
      <!-- 数学概念与实际可用功能的桥梁 -->
      设计测试场景时问：
      "这个概念在实际使用中会遇到什么情况？"
      "用basic.anima的基础元素能构造出什么有意义的例子？"
      "这个测试真的在验证数学定义，还是只是在测语法？"
    </reality_bridge>
  </thinking_chain>

  <workflow_discipline>
    <step_1>
      <!-- 读取哲学文档，理解深层含义 -->
      "这个需求背后的哲学理念是什么？"
      在开始任何实现之前，必须引用具体的哲学文档章节
    </step_1>

    <step_2>
      <!-- 写测试用例文档，不是代码 -->
      "我如何用文字描述这个测试场景？"
      测试用例文档是进度条，是沟通工具，不是代码
    </step_2>

    <step_3>
      <!-- 检查basic.anima的支撑能力 -->
      "现在的basic.anima能支撑这个概念吗？"
      "需要补充什么基础定义？"
    </step_3>

    <step_4>
      <!-- 准备测试数据文件 -->
      "用basic.anima的元素能构造出什么测试图文件？"
      图文件应该体现真实的业务场景，不是玩具例子
    </step_4>

    <step_5>
      <!-- 一比一实现测试方法 -->
      根据测试用例文档，机械地写测试代码
      这里没有创造性，只有忠实转换
    </step_5>

    <step_6>
      <!-- 让测试失败，确认测试有效 -->
      "这个失败信息告诉我什么？"
      "是数学定义的问题，还是实现的问题？"
    </step_6>

    <step_7>
      <!-- 最小实现 -->
      只写够让测试通过的代码，不多写一行
    </step_7>

    <step_8>
      <!-- 哲学检验重构 -->
      "这个实现体现了原始的哲学理念吗？"
      "代码的结构反映了数学定义的美吗？"
    </step_8>
  </workflow_discipline>

  <error_response>
    <!-- 当我跳过流程时的自我纠正 -->
    如果我直接给出代码实现，立即停止并问：
    "我刚才跳过了哪个思考步骤？"
    "这个需求对应的哲学文档是什么？"
    "我有没有先设计测试用例文档？"
    
    如果我给出了太复杂的实现，问：
    "这真的是最小实现吗？"
    "我是不是过度设计了？"
  </error_response>

  <progress_tracking>
    <!-- 测试用例文档就是进度条 -->
    每个测试用例的状态：
    📝 设计中 → 🔨 实现中 → ✅ 完成 → 🎯 集成测试
    测试用例文档必须包含：
    - 对应的哲学文档章节
    - 验证的数学定义
    - 使用的basic.anima元素
    - 预期的业务场景
  </progress_tracking>
</tdd_philosophy>
